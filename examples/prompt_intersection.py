import llamppl as llp

class PromptIntersection(llp.Model):
    # Constructs the model. Should not make any
    # random choices, as it will only be executed
    # one time, before inference begins.
    def __init__(self, prompts):
        super().__init__()
        self.contexts = [self.new_context(prompt) for prompt in prompts]

    def step(self):
        # Generate proposed token
        token = self.sample(llp.Transformer(self.contexts[0]), 
                            proposal=self.locally_optimal_proposal())

            # Observe from other LLMs
        for context in self.contexts[1:]:
            self.observe(llp.Transformer(context), token)

        # Check for eos 
        if token == llp.EOS:
            self.finish()
            return

        # Update generated string
        self.s += token
            
    # Greedy / locally optimal proposal for next token
    def locally_optimal_proposal(self):
        logprobs = map(lambda c: llp.lognormalize(c.logits()), self.contexts)
        p_scores = sum(logprobs)
        q_logprobs = llp.lognormalize(p_scores)
        return llp.TokenCategorical(q_logprobs)

if __name__ == "__main__":
    # Create the model
    llp.LLaMAConfig.set_model_path(input("Path to GGML LLaMA model weights: "))
    prompts = [" My favorite writer is probably", " My favorite physicist is probably"]
    model = PromptIntersection(prompts)
    # Run SMC
    for i, p in enumerate(llp.smc_steer(model, 5, 3)):
        print(f"Particle {i}: {p} (weight {p.weight})")

else:
    llp.LLaMAConfig.set_model_path(llp.WEIGHTS_PATH)